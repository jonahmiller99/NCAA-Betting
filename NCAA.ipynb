{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import requests\n",
    "import time\n",
    "from time import sleep\n",
    "import csv\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import pickle\n",
    "# How to pull all attributes from an xpath\n",
    "# title = hover_spread.get_property('attributes')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "teams = []\n",
    "\n",
    "driver = webdriver.Chrome('/Users/jonahmiller/Downloads/chromedriver 2')\n",
    "driver.get(\"https://barttorvik.com/trank.php?year=2019#\")\n",
    "\n",
    "for i in range(1,104):\n",
    "    team_location = \"/html/body/div[1]/div/table/tbody/tr[{}]\".format(i)\n",
    "    elem = driver.find_element_by_xpath(team_location)\n",
    "    team_name = elem.get_attribute('id')\n",
    "    teams.append(team_name)\n",
    "    \n",
    "\n",
    "scrape_team = []\n",
    "names = []\n",
    "for i in range(len(teams)):\n",
    "    if len(teams[i]) == 0:\n",
    "        continue\n",
    "    names.append(teams[i][1:])\n",
    "check = teams\n",
    "\n",
    "for i in range(len(names)):\n",
    "    teams[i] = names[i]\n",
    "    team = teams[i]\n",
    "    if len(team) == 0:\n",
    "        continue\n",
    "    if '_' in teams[i]:\n",
    "        teams[i] = teams[i].replace('_','+')\n",
    "    if team == 'Saint_Mary_s':\n",
    "        teams[i] = \"Saint+Mary's\"\n",
    "    if team == 'St__John_s':\n",
    "        teams[i] = \"St+John's\"\n",
    "        \n",
    "\n",
    "    scrape_team.append(teams[i])\n",
    "    \n",
    "# Clean up the end of the names \n",
    "\n",
    "for i in range(len(scrape_team)):\n",
    "    last = scrape_team[i][-1]\n",
    "    if last == '+':\n",
    "        ins = scrape_team[i][:-1] + '.'\n",
    "        scrape_team[i] = ins\n",
    "    if scrape_team[i] == 'St++Bonaventure':\n",
    "        scrape_team[i] = 'St.+Bonaventure'\n",
    "        \n",
    "        \n",
    "vals = []\n",
    "stats = []\n",
    "total_team_data = {}\n",
    "for i in range(len(scrape_team)):\n",
    "    stats = []\n",
    "    link = \"https://barttorvik.com/team.php?team={}&year=2019\".format(scrape_team[i])\n",
    "    driver.get(link)\n",
    "    time.sleep(0.2)\n",
    "    vals.append(teams[i])\n",
    "    record = '/html/body/div/div/h1/span'\n",
    "    driver.find_element_by_xpath(record)\n",
    "    for k in range(1,30):\n",
    "        vals = [scrape_team[i]]\n",
    "        hover_link = \"/html/body/div/div/div[2]/div[4]/table/tbody/tr[{}]/td[8]\".format(k)\n",
    "        element_to_hover_over = driver.find_element_by_xpath(hover_link)\n",
    "        hover = ActionChains(driver).move_to_element(element_to_hover_over)\n",
    "        hover.perform()\n",
    "        time.sleep(0.3)\n",
    "        hover_spread = driver.find_element_by_xpath('/html/body/div[2]')\n",
    "        Pregame_Spread = hover_spread.get_attribute('textContent')\n",
    "        vals.append(Pregame_Spread)\n",
    "        for j in range(1,31):\n",
    "            path = \"/html/body/div/div/div[2]/div[4]/table/tbody/tr[{}]/td[{}]\".format(k,j)\n",
    "            elem = driver.find_element_by_xpath(path)\n",
    "            elem = elem.get_attribute('textContent')\n",
    "            vals.append(elem)\n",
    "        stats.append(vals)\n",
    "    total_team_data[scrape_team[i]] = stats       \n",
    "        \n",
    "# THIS CODE WILL GRAB PREGAME SPREAD AND MAYBE PROJECTED SCORE... I THINK \n",
    "# element_to_hover_over = driver.find_element_by_xpath(\"/html/body/div/div/div[2]/div[4]/table/tbody/tr[1]/td[8]\")\n",
    "# hover = ActionChains(driver).move_to_element(element_to_hover_over)\n",
    "# hover.perform()\n",
    "# time.sleep(0.05)\n",
    "# hover_spread = driver.find_element_by_xpath('/html/body/div[2]')\n",
    "# Pregame_Spread = hover_spread.get_attribute('textContent')\n",
    "# print(Pregame_Spread)\n",
    "\n",
    "\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a Solid starting point to work on the problem from, \n",
    "# Would be in my best interest to not overwrite this. \n",
    "\n",
    "# import pickle\n",
    "# pickle_out = open(\"data.pickle\", \"wb\")\n",
    "# pickle.dump(total_team_data, pickle_out)\n",
    "# pickle_out.close()\n",
    "\n",
    "\n",
    "# team_pickle = open(\"teams.pickle\", \"wb\")\n",
    "# pickle.dump(scrape_team, team_pickle)\n",
    "# team_pickle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(teams)):\n",
    "#     name = teams[i]\n",
    "#     if teams[i][-1] == '+':\n",
    "#         teams[i] = teams[i][-1].replace('_','.')\n",
    "#     print(teams[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = webdriver.Chrome('/Users/jonahmiller/Downloads/chromedriver 2')\n",
    "# for i in range(10):\n",
    "#     vals = []\n",
    "#     link = \"https://barttorvik.com/team.php?team={}&year=2021\".format(scrape_team[i])\n",
    "#     driver.get(link)\n",
    "#     vals.append(teams[i])\n",
    "#     record = '/html/body/div/div/div[2]/div[4]/table/tbody/tr[1]'\n",
    "#     driver.find_element_by_xpath(record)\n",
    "#     rec = elem.get_attribute('textContent')\n",
    "    \n",
    "# driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /html/body/div/div/div[2]/div[4]/table/tbody/tr[2]\n",
    "\n",
    "\n",
    "# Here is where I do the bulk of the work.  Using the scraped list of top 100 teams I navigate to their respective \n",
    "# pages which contain 2020 - 2021 season with respective records and game stats.\n",
    "# As the season continues this will continue to get larger and larger\n",
    "# It would make sense to have a system set up to link this data to sql database and then can effeciently manipulate data\n",
    "\n",
    "####  This was combined into one block at the top, left for future reference or in the event that I need to change something\n",
    "# Future idea: Have a live feed of mathchups for the day and then automatically view algo odds \n",
    "\n",
    "\n",
    "# vals = []\n",
    "# driver = webdriver.Chrome('/Users/jonahmiller/Downloads/chromedriver 2')\n",
    "# stats = []\n",
    "# total_team_data = {}\n",
    "# for i in range(len(scrape_team)):\n",
    "#     stats = []\n",
    "#     link = \"https://barttorvik.com/team.php?team={}&year=2021\".format(scrape_team[i])\n",
    "#     driver.get(link)\n",
    "#     vals.append(teams[i])\n",
    "#     record = '/html/body/div/div/h1/span'\n",
    "#     driver.find_element_by_xpath(record)\n",
    "#     for k in range(1,13):\n",
    "#         vals = [scrape_team[i]]\n",
    "#         for j in range(3,31):\n",
    "#             path = \"/html/body/div/div/div[2]/div[4]/table/tbody/tr[{}]/td[{}]\".format(k,j)\n",
    "#             elem = driver.find_element_by_xpath(path)\n",
    "#             elem = elem.get_attribute('textContent')\n",
    "#             vals.append(elem)\n",
    "#         stats.append(vals)\n",
    "#     total_team_data[scrape_team[i]] = stats\n",
    "# driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a list of all the actual column names from the site.\n",
    "# Need to actually walk through the scraping results to see what is pulled,\n",
    "# There are most likely some inconsistencies. \n",
    "\n",
    "Cols = \"‘Opponent’, ‘Result’, ‘Record’, ‘WAB’, ‘ADJO’, “ADJD’, ‘O - PPP’, ‘O - EFG%’, ‘O - TO%’, ‘O - OR%’, ‘O - FTR’, ‘O - 2P’, ‘O - 3P’,  ‘D - PPP’, ‘D - EFG%’, ‘D - TO%’, ‘D - OR%’, ‘D -  FTR’, ‘D -  2P’, ‘D - 3P’, ‘G-SC’, ‘+/-‘\"\n",
    "Cols = Cols.replace(\"‘\", \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(total_team_data)  \n",
    "df.to_csv('total_team_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
