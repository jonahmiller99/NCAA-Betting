{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('git_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inputs = ['Favored Team Cover','Favored Final Spread','Favored Team Rank','Spread','Fav Court', 'Fav Tempo', 'Fav ADJO', \n",
    "              'Fav ADJD', 'Fav O - PPP', 'Fav O - EFG%','Fav D - PPP', 'Fav D - EFG%', 'Underdog Team Rank' , \n",
    "              'Underdog Tempo', 'Underdog ADJO', 'Underdog ADJD', 'Underdog O - PPP', 'Underdog O - EFG%', \n",
    "              'Underdog D - PPP', 'Underdog D - EFG%']\n",
    "\n",
    "X = df[['Fav ADJO', 'Favored Team Predicted Win', 'Fav ADJD','Favored Team Rank', 'Fav O - PPP', 'Underdog ADJO', \n",
    "        'Underdog ADJD', 'Underdog Team Rank', 'Fav Court_H', 'Fav Court_N']]\n",
    "y = df['Favored Final Spread'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a general idea of how close this model performs\n",
    "# input predicted y and y_test\n",
    "# Output the percent of the guesses that are within 1,2,3,4 or less points of final spread\n",
    "\n",
    "def model_performance(y,prediction):\n",
    "    pred = list(prediction)\n",
    "    y_list = list(y)\n",
    "    count_1,count_2,count_3,count_4 = 0,0,0,0\n",
    "    for i in range(len(pred)):\n",
    "        if abs((pred[i]) - y_list[i]) <= 1:\n",
    "            count_1 += 1\n",
    "        if abs((pred[i]) - y_list[i]) <= 2:\n",
    "            count_2 += 1\n",
    "        if abs((pred[i]) - y_list[i]) <= 3:\n",
    "            count_3 += 1            \n",
    "        if abs((pred[i]) - y_list[i]) <= 4:\n",
    "            count_4 += 1            \n",
    "    score_1 = round((count_1/len(pred) * 100),4)\n",
    "    score_2 = round((count_2/len(pred) * 100),4)\n",
    "    score_3 = round((count_3/len(pred) * 100),4)\n",
    "    score_4 = round((count_4/len(pred) * 100),4)\n",
    "    return score_1,score_2,score_3,score_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.321</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.319</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   157.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 13 Jan 2021</td> <th>  Prob (F-statistic):</th>          <td>3.28e-270</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:28:24</td>     <th>  Log-Likelihood:    </th>          <td> -12558.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  3323</td>      <th>  AIC:               </th>          <td>2.514e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  3313</td>      <th>  BIC:               </th>          <td>2.520e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fav ADJO</th>                   <td>   -0.1552</td> <td>    0.037</td> <td>   -4.151</td> <td> 0.000</td> <td>   -0.228</td> <td>   -0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Favored Team Predicted Win</th> <td>    0.4584</td> <td>    0.038</td> <td>   12.045</td> <td> 0.000</td> <td>    0.384</td> <td>    0.533</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fav ADJD</th>                   <td>    0.1348</td> <td>    0.057</td> <td>    2.385</td> <td> 0.017</td> <td>    0.024</td> <td>    0.246</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Favored Team Rank</th>          <td>    0.0168</td> <td>    0.010</td> <td>    1.722</td> <td> 0.085</td> <td>   -0.002</td> <td>    0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fav O - PPP</th>                <td>    0.0749</td> <td>    0.044</td> <td>    1.711</td> <td> 0.087</td> <td>   -0.011</td> <td>    0.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Underdog ADJO</th>              <td>    0.1157</td> <td>    0.041</td> <td>    2.849</td> <td> 0.004</td> <td>    0.036</td> <td>    0.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Underdog ADJD</th>              <td>   -0.1783</td> <td>    0.036</td> <td>   -5.013</td> <td> 0.000</td> <td>   -0.248</td> <td>   -0.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Underdog Team Rank</th>         <td>   -0.0321</td> <td>    0.009</td> <td>   -3.749</td> <td> 0.000</td> <td>   -0.049</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fav Court_H</th>                <td>    5.6892</td> <td>    0.446</td> <td>   12.767</td> <td> 0.000</td> <td>    4.815</td> <td>    6.563</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fav Court_N</th>                <td>    3.6843</td> <td>    0.616</td> <td>    5.980</td> <td> 0.000</td> <td>    2.476</td> <td>    4.892</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>28.091</td> <th>  Durbin-Watson:     </th> <td>   2.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  41.342</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.069</td> <th>  Prob(JB):          </th> <td>1.05e-09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.529</td> <th>  Cond. No.          </th> <td>    862.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                      y   R-squared (uncentered):                   0.321\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.319\n",
       "Method:                 Least Squares   F-statistic:                              157.0\n",
       "Date:                Wed, 13 Jan 2021   Prob (F-statistic):                   3.28e-270\n",
       "Time:                        16:28:24   Log-Likelihood:                         -12558.\n",
       "No. Observations:                3323   AIC:                                  2.514e+04\n",
       "Df Residuals:                    3313   BIC:                                  2.520e+04\n",
       "Df Model:                          10                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================================\n",
       "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------\n",
       "Fav ADJO                      -0.1552      0.037     -4.151      0.000      -0.228      -0.082\n",
       "Favored Team Predicted Win     0.4584      0.038     12.045      0.000       0.384       0.533\n",
       "Fav ADJD                       0.1348      0.057      2.385      0.017       0.024       0.246\n",
       "Favored Team Rank              0.0168      0.010      1.722      0.085      -0.002       0.036\n",
       "Fav O - PPP                    0.0749      0.044      1.711      0.087      -0.011       0.161\n",
       "Underdog ADJO                  0.1157      0.041      2.849      0.004       0.036       0.195\n",
       "Underdog ADJD                 -0.1783      0.036     -5.013      0.000      -0.248      -0.109\n",
       "Underdog Team Rank            -0.0321      0.009     -3.749      0.000      -0.049      -0.015\n",
       "Fav Court_H                    5.6892      0.446     12.767      0.000       4.815       6.563\n",
       "Fav Court_N                    3.6843      0.616      5.980      0.000       2.476       4.892\n",
       "==============================================================================\n",
       "Omnibus:                       28.091   Durbin-Watson:                   2.041\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               41.342\n",
       "Skew:                           0.069   Prob(JB):                     1.05e-09\n",
       "Kurtosis:                       3.529   Cond. No.                         862.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiple Linear Regression\n",
    "# Basic Model with limited variables,\n",
    "# Variables with high p values were removed > 0.1\n",
    "\n",
    "mlr_model = sm.OLS(y, X)\n",
    "results = mlr_model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Regressor RMSE: 10.818551166314018\n",
      "SVM Regressor R^2: 0.06721086836689438\n",
      "SVM Regressor Accuracy Within 3 Points of Actual: 22.9689%\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine Regressor \n",
    "clf = svm.SVR()\n",
    "clf.fit(X_train, y_train)\n",
    "svmr2 = clf.score(X,y)\n",
    "y_pred = np.array(clf.predict(X_test))\n",
    "svm_rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "svm_accuracy = model_performance(y_pred,y_test)[2]\n",
    "\n",
    "\n",
    "svm_r2 = 'SVM Regressor R^2: {}'\n",
    "svm_reg = 'SVM Regressor RMSE: {}'\n",
    "svm_performance = 'SVM Regressor Accuracy Within 3 Points of Actual: {}%'\n",
    "print(svm_reg.format(svm_rmse))\n",
    "print(svm_r2.format(svmr2))\n",
    "print(svm_performance.format(svm_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLR Regression RMSE: 10.142152483171179\n",
      "MLR Regressor Accuracy Within 3 Points of Actual: 24.1725%\n"
     ]
    }
   ],
   "source": [
    "mlr_model = sm.OLS(y_train, X_train).fit()\n",
    "y_pred = mlr_model.predict(X_test)\n",
    "mlr_rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mlr_accuracy = model_performance(y_pred,y_test)[2]\n",
    "\n",
    "\n",
    "mlr_reg = 'MLR Regression RMSE: {}'\n",
    "mlr_performance = 'MLR Regressor Accuracy Within 3 Points of Actual: {}%'\n",
    "print(mlr_reg.format(mlr_rmse))\n",
    "print(mlr_performance.format(mlr_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regressor RMSE: 10.142152483171179\n",
      "Lasso Regressor R^2: 0.17313023811951034\n",
      "Lasso Regressor Accuracy Within 3 Points of Actual Spread: 23.4704%\n"
     ]
    }
   ],
   "source": [
    "lasso = linear_model.Lasso(alpha=0.1)\n",
    "lasso.fit(X_train, y_train)\n",
    "lassor2 = lasso.score(X,y)\n",
    "lasso_pred = np.array(lasso.predict(X_test))\n",
    "lassoRmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "lassoAccuracy = model_performance(lasso_pred, y_test)[2]\n",
    "\n",
    "                 \n",
    "lasso_r2 = 'Lasso Regressor R^2: {}'\n",
    "lasso_rmse = 'Lasso Regressor RMSE: {}'\n",
    "lasso_performance = 'Lasso Regressor Accuracy Within 3 Points of Actual Spread: {}%'\n",
    "print(lasso_rmse.format(lassoRmse))\n",
    "print(lasso_r2.format(lassor2))\n",
    "print(lasso_performance.format(lassoAccuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosted Regressor RMSE: 10.142152483171179\n",
      "Gradient Boosted Regressor R^2: 0.2974058417995673\n",
      "Gradient Boosted Regressor Accuracy Within 3 Points of Actual Spread: 24.3731%\n"
     ]
    }
   ],
   "source": [
    "reg = GradientBoostingRegressor()\n",
    "reg.fit(X_train, y_train)\n",
    "regr2 = reg.score(X,y)\n",
    "reg_pred = np.array(reg.predict(X_test))\n",
    "regRmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "regAccuracy = model_performance(reg_pred, y_test)[2]\n",
    "\n",
    "\n",
    "reg_r2 = 'Gradient Boosted Regressor R^2: {}'\n",
    "reg_rmse = 'Gradient Boosted Regressor RMSE: {}'\n",
    "reg_performance = 'Gradient Boosted Regressor Accuracy Within 3 Points of Actual Spread: {}%'\n",
    "print(reg_rmse.format(regRmse))\n",
    "print(reg_r2.format(regr2))\n",
    "print(reg_performance.format(regAccuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning GBR hyperparameters\n",
    "parameters = {'learning_rate': [0.01,0.02,0.03,0.04,0.2],\n",
    "              'subsample'    : [0.9, 0.5, 0.2, 0.1],\n",
    "              'n_estimators' : [100,200,500,1000],\n",
    "              'max_depth'    : [2,4,6,8,10]\n",
    "             }\n",
    "\n",
    "grid_GBR = GridSearchCV(estimator=reg, param_grid = parameters, cv = 2, n_jobs=-1)\n",
    "grid_GBR.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:  GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.01, loss='ls', max_depth=2,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=None, subsample=0.2, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Best parameters:  {'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 500, 'subsample': 0.2}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Best estimator: ', grid_GBR.best_estimator_)\n",
    "print('Best parameters: ', grid_GBR.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor RMSE: 10.142152483171179\n",
      "Random Forest Regressor R^2: 0.6736032087268671\n",
      "Random Forest Regressor Accuracy Within 3 Points of Actual Spread: 24.5737%\n"
     ]
    }
   ],
   "source": [
    "regr = RandomForestRegressor(random_state=0)\n",
    "regr.fit(X_train, y_train)\n",
    "regrr2 = regr.score(X,y)\n",
    "regr_pred = np.array(regr.predict(X_test))\n",
    "regrRmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "regrAccuracy = model_performance(regr_pred, y_test)[2]\n",
    "\n",
    "regr_r2 = 'Random Forest Regressor R^2: {}'\n",
    "regr_rmse = 'Random Forest Regressor RMSE: {}'\n",
    "regr_performance = 'Random Forest Regressor Accuracy Within 3 Points of Actual Spread: {}%'\n",
    "print(regr_rmse.format(regrRmse))\n",
    "print(regr_r2.format(regrr2))\n",
    "print(regr_performance.format(regrAccuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:  RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=300, n_jobs=None, oob_score=False,\n",
      "                      random_state=0, verbose=0, warm_start=False)\n",
      "Best parameters:  {'max_depth': 5, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "rfr_parameters = {'max_depth': [5,10,15,20,30,50,70], 'n_estimators' : [10,30,50,100,150,200,300],}\n",
    "grid_regr = GridSearchCV(estimator=regr, param_grid = rfr_parameters, cv=4,scoring = 'r2')\n",
    "grid_regr.fit(X, y)\n",
    "print('Best estimator: ', grid_regr.best_estimator_)\n",
    "print('Best parameters: ', grid_regr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ada Boost Regressor RMSE: 10.142152483171179\n",
      "Ada Boost Regressor R^2: 0.18305746863852235\n",
      "Ada Boost Regressor Accuracy Within 3 Points of Actual Spread: 23.5707%\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostRegressor(random_state=0)\n",
    "ada.fit(X_train, y_train)\n",
    "adarr2 = ada.score(X,y)\n",
    "ada_pred = np.array(ada.predict(X_test))\n",
    "adaRmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "adaAccuracy = model_performance(ada_pred, y_test)[2]\n",
    "\n",
    "ada_r2 = 'Ada Boost Regressor R^2: {}'\n",
    "ada_rmse = 'Ada Boost Regressor RMSE: {}'\n",
    "ada_performance = 'Ada Boost Regressor Accuracy Within 3 Points of Actual Spread: {}%'\n",
    "print(ada_rmse.format(adaRmse))\n",
    "print(ada_r2.format(adarr2))\n",
    "print(ada_performance.format(adaAccuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
